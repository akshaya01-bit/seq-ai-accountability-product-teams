# Sequencing AI Recommendations and Accountability Practices in Product Teams

This repository accompanies the proposal:

> **Sequencing AI Recommendations and Accountability Practices in Product Teams:
> Algorithmic Authority, Junior Voice, and Psychological Safety.**

This version of the repo uses **synthetic data only** to illustrate the planned
3 × 2 field experiment:

- Sequencing: AI-first, human-first, interleaved
- Accountability: accountability prompt vs. no prompt

Planned outcomes (as in the proposal):

- Junior critical participation on high-stakes agenda items
- Decision revisions
- Perceived authority of AI vs. human teammates
- Team-level psychological safety and junior voice climate

## Repository structure

- `paper/` – proposal PDF
- `docs/` – short overview of the study and links
- `data/raw/` – synthetic agenda-item dataset
- `data/processed/` – processed panel ready for analysis
- `code/` – scripts to generate synthetic data and example analyses
- `materials/` – example meeting templates, accountability prompt text, survey item stubs

## OSF

I may later create an **OSF project page** that simply hosts the PDF and links
to this GitHub repository. No preregistration has been filed yet.

## How this connects to the proposal

- The PDF in `paper/` is the same proposal I am submitting as a linked
  writing sample for PhD applications.
- The synthetic data and code here illustrate how I would structure and
  analyse the field experiment when I run it with real teams.

